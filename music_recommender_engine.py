# -*- coding: utf-8 -*-
"""music_recommender_engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R_Er9YdFOPKp0SeFUkNf6Nnqu5KfThRJ

# Music Recommendation System using Content-Based Filtering

## Project Overview
This notebook demonstrates a content-based music recommendation system trained on a dataset of tracks with audio features and genres. The goal is to recommend songs to users based on their listening history and preferences using machine learning (K-nearest-neighbours approach).
This is a sub-project to an already existing Django website fetching user's data using Spotify's API (that you can find [HERE](https://github.com/wiktorspryszynski/spotify_music_recommender)), which will be later merged to the said project.

### Key Objectives:
- Load and explore the dataset
- Preprocess the data (handle missing values, scale features)
- Train a machine learning model to recommend songs
- Evaluate model performance
- Merge with Django project

# Loading and exploring the dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data_df = pd.read_csv('data.csv')
genres_df = pd.read_csv('data_w_genres.csv')


data_df.head()

genres_df.head(10)

data_df.describe()

genres_df.describe()

# Plotting important metrics from 'data.csv'
features = ['tempo', 'danceability', 'energy', 'popularity']

# Create subplots
fig, axes = plt.subplots(2, 2, figsize=(10, 8))

axes = axes.flatten()

# Plot each feature
for i, feature in enumerate(features):
    sns.histplot(data_df[feature], kde=True, ax=axes[i])
    axes[i].set_title(f'{feature.capitalize()} Distribution')

plt.tight_layout()
plt.show()

"""# Preprocessing data
Let's see if all is well in the dataset

We can see that data.csv has artists typed out as a list and data_w_genres.csv has artists typed out singularly as a string.

To overcome that and merge these two together (to have a genre column next to songs) I will add a column to data.csv with an artist that comes up first in a list and then merge it based on that one artist later.
"""

import ast

def str_to_list(str_list):
    try:
        return ast.literal_eval(str_list)
    except (ValueError, SyntaxError):
        return []

data_df['artists'] = data_df['artists'].apply(str_to_list)

data_df['first_artist'] = data_df['artists'].apply(lambda x: x[0] if isinstance(x, list) else None)
data_df.head()

missing_values = data_df.isnull().sum()
print(missing_values)

# The result above looks great, not a single column with missing values

# Unfortunately I saw some songs with 'n/a' as their first artist
# Let's see how many 'N/A' we have in the 'first artist' column
n_a_count = data_df[data_df['first_artist'].str.lower() == 'n/a'].shape[0]
n_a_count

data_df[data_df['first_artist'].str.lower() == 'n/a'].head()

"""Looks like we have 12 songs where putting the first artist into another column didn't go well (the first artist was put up as 'n/a').

To handle that we could just remove the rows, as it's just 12 values and all of them are from 1935 (so it's safe to say it wouldn't be of that much use), but we can see that all the songs have other, viable singers listed, so instead let's get rid of the 'n/a' and move the second singer first.
"""

# Getting rid of 'N/A' if it's listed as the first artist
data_df['artists'] = data_df['artists'].apply(lambda x: x[1:] if x[0].lower() == 'n/a' else x)

# seeing if it worked (by checking first track by id from result above)
data_df[data_df['id'] == '0VHoDqq7N5VH1UX93Mdyfj']

"""now for the 12 tracks to be all good and well we have to run the script pulling first_artist into a separate column once more"""

data_df['first_artist'] = data_df['artists'].apply(lambda x: x[0] if isinstance(x, list) else None)
data_df[data_df['first_artist'].str.lower() == 'n/a'].shape[0]

data_df[data_df['first_artist'] == None].shape[0]

"""### Merging datasets
Before the merge we can safely get rid of columns describing an artist from data_w_genres.csv besides 'genre' (e.g. energy	instrumentalness	liveness	loudness).
These are all averages for a given artist and we have this data described much better in data.csv already
"""

genres_df = genres_df[['artists', 'genres']]
# Also let's rename the artists column to just artist
genres_df = genres_df.rename(columns={'artists': 'artist'})
genres_df.head(15)

"""Merge the datasets on 'first_artist' from data.csv and 'artists' from data_w_genres.csv"""

merged_df = pd.merge(data_df, genres_df, left_on='first_artist', right_on='artist', how='left')
merged_df.head()

"""Check if any column has missing values"""

missing_columns = merged_df.isnull().any()
missing_columns

"""We can drop the column 'artist' as it is a duplicate of column 'first_artist' and 'release_date' as we have 'year' of release"""

merged_df = merged_df.drop(columns=['artist', 'release_date'])
merged_df.head()

"""Here's a dataframe of 100 songs I favorited and listened to the most (fetched with Spotify's API with my Django project, link at the top of the page), which we will use as a blueprint to recommend songs based on."""

fetched_df = pd.read_csv('demofile.txt', sep=';', encoding='ISO-8859-1')
fetched_df['explicit'] = fetched_df['explicit'].apply(lambda x: 1 if x is True else 0)
fetched_df['year'] = fetched_df['release_date'].apply(lambda x: int(x[:4]))
fetched_df = fetched_df.rename(columns={'artist_genres': 'genres'})
fetched_df.head()

"""In both dataframes the 'genres' column is a string as opposed to a list, so let's fix that"""

merged_df['genres'] = merged_df['genres'].apply(eval)
fetched_df['genres'] = fetched_df['genres'].apply(eval)

"""Some songs have too many genres linked to them which hurts performance of learning. I will limit them to 3 genres per song max, but to ensure that they're not just first 3 songs from randomly sorted list, I will sort them first based on how popular a genre is."""

from collections import Counter

all_genres = [genre for genres_list in merged_df['genres'] for genre in genres_list]
genre_frequency = Counter(all_genres)
genre_frequency.most_common(10)

len(genre_frequency)

# Plot the distribution of counts relative to the index of the genre
genres, counts = zip(*genre_frequency.most_common())
plt.figure(figsize=(10, 6))
plt.plot(range(len(counts)), counts)
plt.xlabel('Genre Index')
plt.ylabel('Frequency (Number of Tracks)')
plt.title("No. of counts a genre has relative to it's index in a sorted Counter object")
plt.grid(True)

plt.show()

least_common_genres = [item for item in genre_frequency.most_common()[:-10:-1]]
least_common_genres

len_genres = len(genre_frequency)
median_common_genres = [item for item in genre_frequency.most_common()[len_genres//2-5:len_genres//2+5]]
median_common_genres

genre_frequency.most_common()[500]

genre_frequency.most_common()[300]

def find_genre(genre_list, genre):
    idx = 0
    for item in genre_list:
        if item[0] == genre:
            return idx
        idx += 1
    return -1

idx = find_genre(genre_frequency.most_common(), 'zolo')
genre_frequency.most_common()[idx], idx

"""Seeing that there are a total of almost 2.8K genres and 500th's genre count is close to 150 only, I think it's a good idea to limit this number to about 300, as the least common ones are 'weird' and not of much use, but hurt performance greatly. I also want for each track to have 3 genres tops."""

top_300_genres = [item[0] for item in genre_frequency.most_common()[:300]]

def get_top_genres(genres_list, genre_frequency, max_genres, top_genres):
    """
    Function to filter a track's genres by whether they are in the top_genres list,
    sort them by their popularity (frequency), and limit the result to max_genres.
    """
    filtered_genres = [genre for genre in genres_list if genre in top_genres]
    sorted_genres = sorted(filtered_genres, key=lambda genre: genre_frequency.get(genre, 0), reverse=True)
    return sorted_genres[:max_genres]

merged_df['genres_limited'] = merged_df['genres'].apply(lambda x: get_top_genres(x, genre_frequency, max_genres=3, top_genres=top_300_genres))
fetched_df['genres_limited'] = fetched_df['genres'].apply(lambda x: get_top_genres(x, genre_frequency, max_genres=3, top_genres=top_300_genres))

fetched_df.head(20)

fetched_df[fetched_df['genres_limited'].apply(len) == 0].shape[0]

"""# Train the model

Now with genres sorted and limited we can get to teaching the model how to recommend music.<br>Firstly, let's initialize the MultiLabelBinarizer
"""

from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors

# Initialize the MultiLabelBinarizer
mlb = MultiLabelBinarizer()

"""Fit and transform genres in the datasets"""

genres_encoded_fetched = mlb.fit_transform(fetched_df['genres_limited'])
genres_df_fetched = pd.DataFrame(genres_encoded_fetched, columns=mlb.classes_)
genres_encoded_big = mlb.transform(merged_df['genres_limited'])
genres_df_big = pd.DataFrame(genres_encoded_big, columns=mlb.classes_)

"""Now we can select the audio features (aside from gernes) we want to be included in the training.<br>
I decided to take 'duration_ms' out, as I don't think that the length of a song is that important to recommend based on it,<br>as well as 'mode', because weird results started to pop up.
"""

features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',
            'instrumentalness', 'liveness', 'valence', 'tempo',
            'key', 'explicit', 'popularity', 'year']


X_fetched = pd.concat([fetched_df[features], genres_df_fetched], axis=1)
X_big = pd.concat([merged_df[features], genres_df_big], axis=1)

"""Now let's scale the audio features."""

scaler = StandardScaler()

X_big_scaled = scaler.fit_transform(X_big)
X_fetched_scaled = scaler.transform(X_fetched)

num_neighbors = 5
knn = NearestNeighbors(n_neighbors=num_neighbors, algorithm='auto')
knn.fit(X_big_scaled)

# Get recommendations based on user's listening history
distances, indices = knn.kneighbors(X_fetched_scaled)
recommended_indices = indices.flatten()  # All neighbors for all songs in fetched_df
recommendations = merged_df.iloc[recommended_indices]

# Remove duplicates and limit to a certain number (e.g. 50)
recommendations = recommendations.drop_duplicates(subset='id').head(50)

recommendations.head(10)

"""## Evaluating the model's performance - TO BE DONE

It's hard to evaluate a music recommender's performance as music is subjective and so is liking and disliking a certain track.<br>
Let's see, however, how it stands against Spotify API's built-in recommendation endpoint.<br>
"""

#pip install dotenv
#from dotenv import load_dotenv
#import os

#load_dotenv()

#CLIENT_ID = os.getenv("CLIENT_ID")
#CLIENT_SECRET = os.getenv("CLIENT_SECRET")

#seed_tracks = fetched_df['track_id'].head(5).tolist()
#seed_tracks

# continue here

"""## Implementing the model in the Django project

Save the model and dataset as pkl files
"""

import joblib
joblib.dump(mlb, 'mlb.joblib')
joblib.dump(scaler, 'scaler.joblib')
joblib.dump(knn, 'knn_model.joblib')
joblib.dump(merged_df, 'merged_dataset.pkl')
X_big.to_csv('X_big_features.csv', index=False)

"""Uncomment to download the model and dataset

from google.colab import files
files.download('knn_model.joblib')
files.download('X_big_features.csv')
files.download('mlb.joblib')
files.download('scaler.joblib')

Not much more to be seen here, to see the merge with the Django project click the link to my [GitHub repo](https://github.com/wiktorspryszynski/spotify_music_recommender).<br>
As this is the end: **thank you** for going through my project!
"""